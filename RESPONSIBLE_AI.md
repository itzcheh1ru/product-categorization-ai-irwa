# ğŸ¤ Responsible AI Practices

## ğŸ§­ Principles
- âš–ï¸ Fairness: avoid biased prompts; review datasets for representativeness
- ğŸ” Transparency: document model versions and key decisions
- ğŸ” Privacy: sanitize inputs, avoid logging PII, use JWT/API keys
- ğŸ›¡ï¸ Safety: validate outputs, use confidence thresholds and fallbacks

## ğŸ› ï¸ Implementation Hooks
- ğŸ§¼ Input sanitization: `backend/core/security.py::sanitize_input`
- ğŸ“Š Confidence scores on tags/classification
- ğŸ§¾ Audit-friendly logging (avoid raw PII)
- âš™ï¸ Configurable model via env `LLM_MODEL`
- ğŸ—ï¸ Optional API key with `X-API-Key` header

## ğŸ”¬ Evaluation
- ğŸ” Offline tests for precision@k/recall@k on search suggestions
- ğŸ‘€ Human review for attribute extraction correctness
- ğŸ§ª Prompt iteration with example bank and regression checks

## ğŸ“ Guidance for Report/Viva
- Explain how data is sanitized and stored (no PII logs)
- Show examples demonstrating fairness and mitigations
- Include model/version provenance and change logs


